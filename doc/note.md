## RDB

> 触发机制

1. 满足配置文件中的save规则；
2. 执行flushall命令；
3. 退出Redis(关闭Redis服务)。

> 如何恢复RDB文件

1. 将RDB文件放置在Redis启动目录，Redis启动的时候就会自动检查dump.rdb恢复数据。

优点：

1. 适合大规模的数据恢复；
2. 对数据完整性要求不高

缺点：

1. 需要一定的时间间隔进行操作，如果Redis意外宕机，最后一次快照之后的数据会丢失；
2. fork进程，需要额外的内存开销。

## AOF

类似于操作日志，恢复数据时回放appendonly.aof。

如果aof文件有错误，Redis将无法启动，Redis提供了`redis-check-aof --fix`修复aof文件。

```yml
appendonly no #默认不开启aof模式，默认使用rdb模式
appendfilename "appendonly.aof" #持久化文件的名字
appendfsync always #每次修改都会sync everysec:每秒执行1次sync，可能会丢失这1秒的数据 no:操作系统自己同步数据
```

缺点：

1. 数据文件：aof远大于rdb，恢复速度也更慢；
2. aof运行效率也比rdb慢。

> 重写规则

```yml
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

如果aof文件大于64mb了，fork一个新的进程来重写文件。

## RDB-AOF混合

Redis4.0版本之后，aof-use-rdb-preamble: yes开启。

**新的aof文件前半段是rdb格式的全量数据后半段是aof格式的增量数据**

当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以rdb方式写入aof文件，然后在将重写缓冲区的增量命令以aof方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有rdb格式和aof格式的aof文件替换旧的的aof文件。

当我们开启了混合持久化时，启动redis依然优先加载aof文件，aof文件加载可能有两种情况如下：

1. aof文件开头是rdb的格式, 先加载 rdb内容再加载剩余的 aof；
2. aof文件开头不是rdb的格式，直接以aof格式加载整个文件。

## 发布订阅

subscribe channel 订阅频道

unsubscribe channel 取消订阅频道

publish channel message 将消息发送到指定的频道

> 原理

redis-server里维护一个字典, key是频道, value则是一个链表, 链表中保存了所有订阅了这个channel的客户端。

通过PUBLISH命令向订阅者发送消息, redis-server会使用给定的频道作为键, 在它所维护的channel字典中查找记录了订阅这个频道的所有客户端的链表, 遍历这个链表, 将消息发布给所有订阅者。

## 主从复制

主从复制, 是指将一台Redis服务器的数据, 复制到其他的Redis服务器。前者称为主节点(master/leader) , 后者称为从节点(slave/follower) ; **数据的复制是单向的 ; 只能由主节点到从节点**。Master以写为主, Slave以读为主。

作用:

1. **数据冗余**:主从复制实现了数据的热备份, 是持久化之外的一种数据冗余方式;
2. **故障恢复**:当主节点出现问题时, 可以有从节点提供服务, 实现快速的故障恢复;
3. **负载均衡**:在主从复制的基础上, 配合读写分离, 可以有主节点提供写服务, 由从节点提供读服务, 分担服务器负载;
4. **高可用**

![](img/image-20220215224640520.png)

```shell
> info replication #查看当前库信息
# Replication
role:master #角色 master
connected_slaves:0 #从机数量
master_replid:038c1bdb823d591398b8d97c7ed35569ba9656be
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
```

从机执行命令选择主机

slaveof 127.0.0.1 6379

使用命令配置是暂时的，修改配置文件：

replicaof 配置主机地址即可

![](img/230314.png)

> 细节

主机可以写，从机不能写只能读，主机中的所有信息和数据都会自动被从机保存。

没有哨兵的情况下，即使主机宕机，从机连接的主机依然是之前的主机。主机恢复，集群依然可用。如果从机宕机，从机重启后(并且变为从机)，立马就会从主机中取到值。

**复制原理**

slave启动成功连接到master后会发送一个sync同步命令, master接受命令, 启动后台的存盘进程, 同时收集所有接收到的用于修改数据集命令, 在后台进程执行完毕之后, master将传送整个数据文件到slave, 并完成一次完全同步。

- 全量复制 : slave服务在接收到数据库文件数据后, 将其存盘并加载到内存中;
- 增量复制 : master继续将新的所有收集到的修改命令依次传给slave, 完成同步。

重新连接master，一定执行一次全量复制, master继续将新的所有收集到的数据传给slave, 即增量复制。

使自己变为主节点：slave no one

## 哨兵模式

哨兵是一个独立的进程，独立运行。哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。

作用：

1. 通过发送命令，让Redis服务返回其运行状态，包括主服务器和从服务器；
2. 当哨兵监测到master宕机，会自动从salve选举master，然后通过发布订阅通知其它Redis服务，修改配置文件，让它们切换主机。

![image-20220216195152260](img/image-20220216195152260.png)

多哨兵模式：

![image-20220216195643568](img/image-20220216195643568.png)

假设主服务器宕机，哨兵1先监测到这个结果，系统并不会马上进行故障转移过程，仅仅是哨兵1主观的认为主服务器不可用(主观下线)，当后面的哨兵监测到主服务器不可用，并且数量达到一定值时，那么哨兵之间会进行一次投票，投票的结果由一个哨兵发起，进行故障转移操作。切换成功后，通过发布订阅模式，让各个哨兵把自己监控的从服务器切换主机，这个过程称为客观下线。

> 配置

```yml
#sentinel monitor 被监控的名称 host port 投票
sentinel monitor redis 127.0.0.1 6379 1
```

启动：

```shell
ln -s /usr/local/bin/redis-sentinel /usr/bin/redis-sentinel   #建立软连接,否则找不到命令
redis-sentinel myconfig/sentinel.conf  #启动哨兵
```

如果master节点宕机了，会从slave中选举一个成为master，并把其它slave的主机修改为新的master；如果之前的master恢复了，只能归并到新的master下，当作从机。

**优点：**

1. 基于主从复制，拥有其优点；
2. 主从切换，故障转移，高可用；
3. 健壮性高。

**缺点：**

1. 在线扩容麻烦；
2. 哨兵模式配置比较复杂。

```yml
# Example sentinel.conf

# 哨兵sentinel实例运行的端口 默认26379
port 26379          # 如果有哨兵集群, 我们还需要配置每个哨兵端口

daemonize no

pidfile /var/run/redis-sentinel.pid

logfile ""

# 哨兵的 sentinel的工作目录
dir /tmp            

# 哨兵 sentinel 监控的 redis 主节点 ip port
# master-name 可以自己命名的主节点名字  只能由字母 A-Z  数字0-9 这三个字符".-_" 组成
# quorum 配置多少个 sentinel 哨兵统一认为 master主节点失联, 那么这时候客观上认为主节点失联了
# sentinel monitor <master-name> <ip> <redis-port> <quorum>
sentinel monitor mymaster 127.0.0.1 6379 2

# 当Redia实例中开启了 requirepass foobared 授权密码 这样所有的连接Redis 实例的客户端都要提供密码
# 设置哨兵 sentinel 连接主从密码, 注意必须为主从设置一样的验证密码
# sentinel auth-pass <master-name> <password>
sentinel auth-pass mymaster MySUPER--secret-0123passw0rd

# 指定多少毫秒之后, 主节点没有应答哨兵 sentinel 此时 哨兵主管上认为节点下线 默认 30s
# sentinel down-after-milliseconds <master-name> <milliseconds>
sentinel down-after-milliseconds mymaster 30000

# 这个配置项指定了发生 failover 主备切换时最多有多少个slave同时对新的master 进行同步
# 这个数字越小 完成 failover 所需时间就越长
# 但是如果这个数字越大, 就意味着越多的 slave 因为 replication而不可用
# 可以通过这个值设置为1 来保证每次只有一个 slave 处于不能处理命令的请求状态
# sentinel parallel-syncs <master-name> <numreplicas>
sentinel parallel-syncs mymaster 1

# sentinel failover-timeout <master-name> <milliseconds>
# 故障转移超时时间 failover-timeout 可以用在以下这些方面
# 1 同一个 sentinel 对同一个master两次 failover 之间的间隔时间
# 2 一个 slave 从一个错误的 master 那里同步数据开始计算时间, 直到 slave 被纠正为正确的 master 那里同步数据时
# 3 当想要取消一个正在进行的 failover 所需要的时间
# 4 当进行 failover 时, 配置所有 slaves 指定新的 master 所需要的最大时间. 不过, 即使过了这个超时, slave 依然会被正确的配置为指向 master 但是就不按 paralle1- syncs 所配置规来了
# 默认3分钟
sentinel failover-timeout mymaster 180000

# SCRIPTS EXECUTION
# 配置当某一件事情发生时, 所需要执行的脚本, 可以通过脚本通知来通知管理员, 例如当系统不能正常发邮件通知相关人员
# 对于脚本的运行结果有以下规则
# 若脚本执行后返回1, 那么该脚本稍后将会被再次执行, 重复次数默认为 10
# 若脚本执行后返回2, 或者比2更高的一个返回值, 脚本将不会重复执行
# 如果脚本在执行过程中由于收到系统中断信号被终止了, 则同返回值1时的行为相同
# 一个脚本的最大执行时间为60s, 如果超过了这个时间, 脚本将会被一个SIGKILL信号终止, 之后重新执行 
# sentinel notification-script <master-name> <script-path>
sentinel notification-script mymaster /var/redis/notify.sh

#客户端重新配置脚本
#当一个master由于failover而发生改变时,这个脚本将会被调用,通知相关的客户端关于master地址已经发生改变的信息.
#将以下参数传递给脚本：
#<master name><role><state><from ip><from port><to ip><to port>
#当前<state>始终是“failover”
#<role>是“leader”或“observer”中的一个
#参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的
#此脚本应该是通用的,能被多次调用, 不是针对性的。
#sentinel client-reconfig-script <master-name> <script-path>
sentinel client-reconfig-script mymaster /var/redis/reconfig.sh

# SECURITY
# 默认情况下，SENTINEL SET将无法在运行时更改通知脚本和客户端重新配置脚本。这避免了一个微不足道的安全问题，客户机可以将脚本设置为任何值，并触发故障转移以执行程序。
sentinel deny-scripts-reconfig yes
```

## 缓存穿透

查询数据，Redis内存数据中不存在(缓存没有命中)，于是向持久层数据库查询，数据库中也不存在。当并发量过大时，频繁请求持久层数据库，数据库压力过大，可能因此宕机导致整个系统不可用。

解决方案：

- 布隆过滤器

  一种数据结构，对所有可能查询的参数以hash形式存储，控制层先进行校验，不符合则丢弃，从而避免了对底层存储系统的查询压力。

- 缓存空对象

  当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据将从缓存中缓存中获取，保护了持久层数据库。

  缺点：

  1. 如果空值需要缓存起来，这就意味着缓存需要更多的空间存储更多的键；
  2. 即使对空置设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间不一致。

## 缓存击穿

一个key非常热点，在这个key在失效的瞬间，持续的大并发就会穿破缓存，直接请求数据库，会导致数据库瞬间压力过大。

解决方案：

- 设置热点数据不过期

  会导致缓存永不过期

- 互斥锁

  使用分布式锁，保证每个key同时只有一个线程去查询后端服务，其它线程没有获得分布式锁，只能等待。

## 缓存雪崩

某一个时间段，缓存集中过期失效/Redis宕机。请求集中落在持久层数据库，导致数据库压力过大。

解决方案：

- 缓存过期时间设为随机值
- 使用快速失败的熔断策略，减少数据库瞬间压力
- 使用集群模式和哨兵模式尽量保证缓存服务的高可用

## 分布式锁



## 一致性



## 过期策略





![](img/redis画像图.png)

# 数据结构

数据类型：String，List，Hash，Set，Sorted Set

数据结构：简单动态字符串，双向链表，压缩列表，哈希表，跳表，整数数组

![Redis数据结构](img/Redis数据结构.png)

**rehash**

1. 给哈希表2分配更大的空间，如哈希表1大小的两倍；
2. 把hash表1的数据重新映射并拷贝到哈希表2中；
3. 释放哈希表1的空间

**渐进式rehash**

第2步拷贝数据时，Redis仍然正常处理请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺带将这个索引位置上的所有entries拷贝到哈希表2中，等处理下一个请求时，再顺带拷贝哈希表1中的下一个索引位置的entries。

![渐进式rehash](img/image-20220411162617215.png)

查找时间复杂度

![查找时间复杂度](img/image-20220412090541543.png)

# Redis单线程为什么这么快？

Redis的网络IO和键值对读写是由一个线程完成的，即Redis对外提供键值存储服务的主要流程。但Redis的其它功能，如持久化、异步删除、集群数据同步等操作，是由额外线程处理的。

1. 大部分操作在内存上完成；
2. 采用了高效的数据结构；
3. 多路复用机制。

**基于多路复用的高性能I/O模型**

在Redis只运行**单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。**一旦有请求到达，就会交给Redis线程处理。为了在请求到达时能够通知到Redis线程，**Redis网络框架调用epoll机制，内核监听这些套接字，select/epoll提供了基于事件的回调，一旦监测到有请求到达，就触发相应的事件，将这些事件放入事件队列，Redis单线程不断处理事件队列。**

![](img/image-20220412162725156.png)

# AOF日志

**写后日志**：Redis先执行命令，将数据写入内存，然后才记录日志。

AOF日志记录Redis执行的命令，避免额外的检查开销，只有命令执行成功，才会记录到AOF日志。**避免记录错误命令，不会阻塞当前的写操作。**风险：**数据丢失，阻塞下一个写操作。**

**三种回写策略**

- Always：同步写回，即每个写命令执行完，立马同步的将日志写回磁盘；
- Everysec：每秒写回，每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔1秒把缓冲区中的内容写入磁盘；
- No：操作系统控制的写回，每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区中的内容写入磁盘。

![image-20220413101431432](img/image-20220413101431432.png)

**AOF重写机制**

Redis根据数据库现状创建一个新的AOF文件，即读取数据库中所有键值对，然后对每一个键值对用一条命令记录它的写入。重写机制具有"多变一"，可以把日志文件变小。

**AOF重写过程**

"一个拷贝，两处日志"：

1. 主线程fork出后台的bgrewriteaof子进程，此时，fork会把主线程的内存(数据的虚实映射)拷贝一份给bgrewrite子进程，包含数据库的最新数据；

2. 主线程未阻塞，仍可以处理新来的操作。如果来了写操作，Redis把这个操作记录到正在使用的AOF日志缓冲区；

3. 第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。

   ![AOF重写过程](img/image-20220413110900819.png)

# RDB日志

内存快照，内存中的数据在某一时刻的状态记录。相比AOF，RDB记录的是某一时刻的数据，并不是操作。在数据恢复时，可以直接把RDB文件读入内存，很快的完成恢复。

**save**：在主线程中执行，会导致阻塞；

**bgsave**：fork子进程，专门用于写入RDB文件，避免了主线程的阻塞，默认配置。

写时复制(Copy-On-Write，COW)

1. bgsave子进程是由主线程fork生成的，可以共享主线程的所有内存数据。bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件；

2. 如果主线程对这些数据都是读操作，那么主线程和bgsave子进程相互不影响；如果主线程要修改一块数据，那么这块数据会被复制一份，生成该数据的副本。然后bgsave子进程会把这个副本数据写入RDB文件，这个过程中，主线程仍然可以修改原来的数据。

   ![写时复制机制保证快照期间数据可修改](img/image-20220414143135376.png)

频繁执行全量快照的开销：全量数据写入磁盘的压力；主线程fork子进程时的开销。

**混合使用AOF和RDB日志**

RDB以一定的频率执行，在两次RDB之间，使用AOF日志记录期间的所有命令操作。

![内存快照和AOF混合使用](img/image-20220414143657678.png)

# 主从数据库如何实现数据一致？

Redis提供了主从库模式，以保证数据副本的一致，主从库之间采用读写分离。

读操作：主库、从库都可以接收；

写操作：首先到主库执行，然后，主库将写操作同步给从库。

**主从库间第一次同步**

![redis同步过程](img/image-20220418152121724.png)

1. 主从库建立连接、协商同步：从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了；
2. 主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到RDB 文件后，会先清空当前数据库，然后加载 RDB 文件
3. 主库会把第二阶段执行过程中新收到的写命令，再发送给从库。当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。

**主从级联模式分担全量复制时的主库压力**

通过"主-从-从"模式将主库生成RDB和传输RDB的压力，以级联的方式分散到从库上。

![级联的"主-从-从"模式](img/级联的主-从-从模式.png)

一旦主从库完成了全量的复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续收到的命令操作再同步给从库，这个过程称为**基于长连接的命令传播**，可以避免频繁建立连接的开销。

**主从库间网络断了怎么办？**

2.8之前，全量复制；2.8之后，增量复制，只会把主从库网络断连期间主库收到的命令同步给主库。

主从库断链后，主库会把断连期间收到的写操作命令，写入replication buffer，同时也会把这些操作命令写入repl_backlog_buffer这个缓冲区。

repl_backlog_buffer是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己读到的位置。**

主库偏移量：master_repl_offset

从库偏移量：slave_repl_offset

![Redis增量复制流程](img/image-20220418163623333.png)

如果从库的读取速度比较慢，有可能导致从库还未读取的操作被主库新写的操作覆盖了，导致主从库数据不一致。

调整repl_backlog_size，缓冲空间大小 = 主库写入速度命令 * 操作大小 - 主从库间网络传输命令速度 * 操作大小，repl_backlog_zie = 缓冲空间大小 * 2

# 哨兵模式

**基本流程**

哨兵其实就是一个运行在特殊模式下的Redis进程，主从库实例运行的同时，它也在运行，哨兵主要负责的三个任务：**监控、选主和通知**。

- 监控：哨兵进程，周期性的给所有的主从库发送PING命令，检测它们是否正在运行，如果没在规定时间内响应哨兵的PING命令，标记为下线状态，主库下线，还会开始**自动切换主库**的流程。

- 选主：主库挂了之后，哨兵需要按照一定的规则在存活的从库中选择一个实例，作为新的主库。

- 通知：哨兵把新主库的连接信息发给其他从库，让它们执行replicaof命令，和主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发送到新主库上。

  ![image-20220421092736807](img/image-20220421092736807.png)

**主观下线和客观下线**

哨兵进程会使用PING命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果检测的是从库，哨兵简单地把它标记为"主观下线"就行了，如果检测的是主库，**集群网络压力较大，网络拥塞，或者是主库本身压力大的情况**下，可能存在误判的情况。

**通常会采用多实例组成的集群模式进行部署，即哨兵集群。**

当有N个哨兵实例时，最好要有N/2 + 1个实例判断主库为"主观下线"，才能最终判定为"客观下线"。

![image-20220421094414358](img/image-20220421094414358.png)

**如何选定新主库？**

筛选+打分

哨兵会按照在线状态、网络状态、筛选过滤掉一部分不符合要求的从库，然后按照从库优先级、从库复制进度、从库ID号大小对剩余的从库打分，只要有得分高的从库出现，就把它选为新的主库。

![image-20220421095137558](img/image-20220421095137558.png)

- 筛选：除了检查从库的当前在线状态，还要判断它之前的网络连接状态。

  配置项：sentinel down-after-milliseconds * 10，如果在down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了，如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。

- **打分：**从库优先级、从库复制进度、从库ID号。

  1. 优先级高的从库得分高

     slave-priotity配置项，给从库设置不同的优先级。

  2. 和旧主库同步程度最接近的从库得分高

     slave_repl_offset最最接近master_repl_offset

  3. ID号小的从库得分高


# 哨兵集群

**基于pub/sub机制的哨兵集群组成(发布订阅机制)**

只有订阅了同一个频道的应用，才能通过发布的消息进行信息发布。主从集群中，主库上一个名为"_ _sentinel__:hello"的频道，不同哨兵就是通过它来相互发现、通信的。

哨兵1把自己的IP和端口发布到"_ _sentinel__:hello"频道，哨兵2、3订阅了该频道，那么此时哨兵2、3就可以直接获取哨兵1的IP地址和端口号，哨兵2、3可以和哨兵1建立网络连接了。

![image-20220424162534818](img/image-20220424162534818.png)

哨兵还需对主从库进行心跳判断，还需要通知从库和新主库进行同步。

哨兵向主库发送INFO命令，主库就会把从库列表返回给哨兵。

![image-20220424165826083](img/image-20220424165826083.png)

**基于pub/sub机制的客户端事件通知**

哨兵就是一个运行在特定模式下的Redis实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。每个哨兵实例也提供pub/sub机制，客户端可以从哨兵订阅消息。

![image-20220424170857799](img/image-20220424170857799.png)

如订阅"所有实例进入客观下线状态的事件"：

```shell
SUBSCRIBE +odown
```

订阅所有事件：

```shell
PSUBSCRIBE *
```

**由哪个哨兵进行主从切换？**

![image-20220424172424495](img/image-20220424172424495.png)

任何一个实例只要自身判断主库"主观下线"后，就会给其他实例发送is-master-down-by-addr命令，其他实例根据与主库的连接情况，做出Y或N的响应，如果**赞成票数达到了配置文件中的quorum配置项**设定的，就可以标记主库为"客观下线"。

这个哨兵向其他哨兵发送命令，希望由自己执行主从切换，需要满足两个条件：

1. 拿到半数以上的赞成票；
2. 票数大于等于配置文件中的quorum值。

**至少配置3个哨兵实例，要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值down-after-milliseconds。**

# 切片集群：数据增多了，是该加内存还是加实例？

**切片集群(分片集群)**

启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分成多分，每一份用一个实例来保存。

**如何保存更多数据？**

- 纵向扩展

  升级单个Redis实例的资源配置，如增加内存容量、磁盘容量、使用更高配置的CPU等。

  优点：

  1. 实施简单

  缺点：

  1. 数据量增加，需要的内存也会增加，主线程fork子进程时可能会阻塞；
  2. 受硬件成本限制

- 横向扩展

  横向增加Redis实例的个数。

  优点：

  1. 硬件成本低

  缺点：

  1. 多实例的分布式管理复制

     数据切片后，在多个实例之间如何分布？

     客户端怎么确定想要访问的数据在哪个实例上？

**数据切片和实例的对应分布关系**

Redis Cluster方案采取哈希槽(Hash Slot)来处理数据和实例之间的映射关系。一个切片集群共有16384个哈希槽，每个键值对都根据它的key，被映射到一个哈希槽中。

1. 根据键值对的key，按照CRC16算法计算一个16bit的值
2. 用这个16bit的值对16384取模，得到一个相应编号的哈希槽

部署Redis Culster方案时，使用cluster create命令创建集群，Redis会自动把这些槽平均分配在集群实例上。如16384/N。

也可以使用cluster meet命令手动简历实例间的连接，形成集群。再使用cluster addslots命令，指定每个实例上的哈希槽个数(更适合Redis实例的内存大小不一)。**在手动分配哈希槽时，需要把 16384 个槽都分配完，否则**
**Redis 集群无法正常工作。**

**客户端如何定位数据？**

1. 客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端；
2. Redis实例会把自己的哈希槽信息发给和它相连接的其它实例；
3. 客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后给相应的实例发送请求。

- 变化

  1. 集群中，实例有新增或删除，Redis需要重新分配哈希槽；
  2. 为了负载均衡，Redis需要把哈希槽在所有实例上重新分配一遍。

  客户端缓存的分配信息和最新的分配信息不一致。

  **重定向机制**：客户端给一个实例发送数据读写操作时，这个实例上没有相应的数据，客户端再给一个新实例发送操作命令。

  当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么实例就返回MOVED命令响应结果，**同时更新本地缓存**

  ```shell
  GET hello:key
  (error) MOVED 13320 172.16.19.5:6379
  #哈希槽13320 在172.16.19.5实例
  ```

  ![image-20220630210616103](img/image-20220630210616103.png)

  如果客户端给实例2发送请求，但Slot2中的数据只部分迁移到实例3。客户端会收到ASK报错信息：

  ```shell
  GET hello:key
  (error) ASK 13320 172.16.19.5:6379
  ```

  客户端需要先给172.16.19.5实例发送一个ASKING命令，让这个实例允许执行客户端接下来执行的命令，然后客户端再向这个实例发送GET命令。

  ![image-20220630211248490](img/image-20220630211248490.png)

  ASK命令并不会更新客户端缓存的哈希槽分配信息。

# 答疑

## 整数数组和压缩列表作为底层数据结构的优势是什么？

"又快又省"

**节省内存空间**：整数数组和压缩列表都是在内存中分配一块地址连续的空间，元素挨个连续放置，非常紧凑，切不用通过额外的指针把元素串接起来，避免额外指针带来的空间开销。

## AOF重写过程中其他潜在的阻塞风险

1. Redis主线程fork创建bgrewriteaof子进程时，内核需要创建用于管理子进程的相关数据结构(进程控制块，PCB)，内核需要把主线程的PCB内容拷贝给子进程，创建和拷贝由内核执行，有阻塞主线程的风险。而且子进程要拷贝父进程的页表，Redis实例内存大，页表就大，fork执行时间会长，会给主线程带来阻塞风险。
1. bgrewriteaof子进程和主线程共享内存。当主线程收到新写或修改操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是bigkey，主线程会因为申请大空间而面临阻塞。

## AOF重写为什么不共享使用AOF本身的日志

都用AOF日志的话，主线程要写，bgrewriteaof子进程也要写，两者会竞争文件系统的锁，影响主线程的性能。

## 4GB内存，2核CPU，写读操作比例：8 : 2，已有数据量大小约2GB，RDB持久的风险

1. 内存不足风险

   写时复制需要给写操作的数据分配新的内存空间，2G * 0.8 = 1.6GB，内存使用量接近饱和，如果有新的key写入或修改，开启Swap：数据写入磁盘，性能下降；未开启Swap：OOM

2. 主进程和子进程竞争使用CPU风险

   生成RDB的子进程需要CPU核运行，主线程本身也需要CPU核运行，如果还有其它后台线程，此时会竞争CPU资源。

## 为什么主从库间复制不使用AOF?

1. RDB二进制文件，写入磁盘、网络传输效率更高；
2. 从库恢复数据的时候，RDB效率更高。

## 在主从切换过程中，客户端能否正常地进行请求操作？

主从集群一般采用读写分离的方式，主库故障之后，客户端仍然可以把读请求发送给从库，但对于写请求操作，客户端就无法执行了。

## 如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么？

1. 客户端可以缓存写请求；
2. 主从切换完成后，客户端和新主库建立连接，哨兵需要提供订阅频道，让客户端可以订阅到新主库。同时，客户端也需要可以主动和哨兵通信，询问新主库的信息。

## 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？

认为主库“主观下线”的哨兵个数要**大于等于quorum 值**，可以正常判断主库"客观下线"；**主从切换，需要获得半数以上哨兵投票**，无法进行主从切换。

## 哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？

哨兵实例越多，误判率越低。但主从切换的时间也会变久，客户端堆积较多请求，可能会导致客户端请求溢出，从而导致请求丢失。

调大down-after-milliseconds，导致主库实际已经发生故障，但哨兵过了很久才判断出来，影响Redis对业务的可用性。

## 为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？

如果键值对和实例的对应关系发生了变化(如实例增减、数据重新分布)，就要修改表。单线程：所有操作串行，性能慢；多线程：涉及到加锁。

基于哈希槽计算，虽然也要记录哈希槽和实例的对应关系，但哈希槽的个数要比键值对的个数少很多。

## replication buffer 和 repl_backlog_buffer 的区别

replication buffer：主从库在进行全量复制时，主库上用于和从库连接的客户端buffer；

repl_backlog_buffer：支持从库增量复制，主库上用于持续保存写操作的一块专用buffer。

# String

- int编码方式

  64位有符号整位

  保存为一个8字节的Long类型整数

- embstr编码方式

  数据中包含字符，且字符串小于等于44字节时

  简单动态字符串(SSD)

  ![image-20220720211250499](img\image-20220720211250499.png)

  buf：字节数组，保存实际数据。Redis会自动在数组最后增加"\0"表示结束，额外占用1个字节；

  len：占4个字节，表示buf的已用长度；

  alloc：占4个字节，表示buf实际长度，一般大于len。

  RedisObject

  元数据：最后一次访问的时间、被引用的次数等。

  ![image-20220720211903181](img/image-20220720211903181.png)

  当保存的是Long类型整数时，RedisObject中的指针直接赋值为整数数据，节省了指针的空间开销。

  embstr编码：当保存的是字符串数据，并且字符串小于等于44字节时，RedisObject中的数据、指针和SDS是一块连续的内存区域，避免内存碎片。

- raw编码方式

  数据中包含字符，且字符长度大于44

  SDS分配独立空间，并用指针指向SDS。

  ![image-20220720212549623](img/image-20220720212549623.png)

Redis会使用一个全局哈希表保存所有键值对，哈希表的每一项都是一个dictEntry的结构体，用来指向一个键值对。dictEntry的结构有三个8字节的指针，分别指向key、value及下一个dictEntry，共24字节。Redis使用的内存分配库jemalloc，比N大，最接近2的幂次数，减少频繁分配的次数，即32字节。

![image-20220720213543638](img/image-20220720213543638.png)

 Key：10 位数的图片 ID Value：10 位数的图片存储对象 ID

(RedisObject元数据8字节 + 直接赋值整数数据8字节) * 2 + dictEntry32字节 = 64字节

# 压缩列表(ZipList)

![image-20220720213821840](img/image-20220720213821840.png)

表头：

- zlbytes：列表长度
- zltail：列表尾的偏移量
- zllen：列表中entry个数

表尾

- zlend：列表结束

Entry：

- prev_len：前一个entry的长度，1字节：上一个entry的长度小于254字节(255被zlend使用)，5字节：
- len：自身长度，4字节；
- encoding：编码方式，1字节；
- content：保存实际数据。

entry连续放置内存中，不需要额外的指针进行连接。

每个entry保存一个图片存储对象ID(content 8字节) + pre_len(1字节) + 编码方式(1字节) + 自身长度len(4字节) =>16字节

Redis基于压缩列表实现了List、Hash、SortedSet，节省了dictEntry的开销。采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。

# 集合的应用

- 聚合统计

- 排序统计

  Sorted Set

- 二值统计

  用户签到(1)或未签到(0)，Bitmap

  记录用户 8 月 3 号已签到

  ```shell
  #SETBIT key offset value
  SETBIT uid:sign:3000:202008 2 1
  ```

  检查用户 8 月 3 日是否签到

  ```shell
  GETBIT uid:sign:3000:202008 2
  ```

  统计用户在 8 月份的签到次数

  ```shell
  BITCOUNT uid:sign:3000:202008
  ```

- 基数统计

  网页UV

  HyperLogLog：当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。

  把访问页面的每个用户都添加到 HyperLogLog 中

  ```shell
  PFADD page1:uv user1 user2 user3 user4
  ```

  获得 page1 的 UV 值

  ```shell
  PFCOUNT page1:uv
  ```

![image-20220721113851834](img/image-20220721113851834.png)

# 消息队列

![image-20220721151137949](img/image-20220721151137949.png)

# Redis阻塞点

**客户端：**网络IO，键值对增删改查，数据库操作；

**磁盘：**生成RDB快照，记录AOF日志，AOF日志重写；

**主从节点：**主库生成、传输RDB文件，从库接收RDB文件、清空数据库、加载RDB文件；

**切片集群实例：**向其他实例传输哈希槽信息，数据迁移。

![image-20220721151559399](img/image-20220721151559399.png)

- 客户端

  网络IO：IO多路复用机制

  **增删改查：1. 集合全量查询和聚合操作；2. bigkey删除**

- 磁盘

  RDB快照、AOF日志重写：子进程

  **AOF日志同步**

- 主从节点

  主库生成、发送RDB文件：子进程

  **从库清空数据库(FLUSHDB)**

  **加载RDB文件**

- 切片集群

  渐进式

**异步机制**

bigkey删除，AOF日志同步，清空数据库。

![image-20220721153114883](img/image-20220721153114883.png)

异步键值对删除：Redis4.0后提供UNLINK

异步清空数据库：FLUSHDB ASYNC/FLUSHALL ASYNC

# Redis真的变慢了吗？

```shell
./redis-cli --intrinsic-latency 120
#Redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了
```

**慢查询命令**

查看Redis日志、latency monitor工具，定位慢查询命令

1. 用其他高效命令代替；
2. 排序、交集、并集操作时，在客户端完成。

**过期key操作**

默认，Redis每100ms会删除一些过期的key

1. 采样ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP(默认20)个数的 key，并将其中过期的key 全部删除；
2. 如果超过25%的key过期了，重复删除过程，直到过期 key 的比例降至 25% 以下。

**删除操作是阻塞的**，触发第二条会一直执行删除操作(**频繁使用带有相同时间参数的EXPIREAT命令设置过期key**)。

**文件系统：AOF模式**

![image-20220721161015810](img/image-20220721161015810.png)

everysec：Redis 会使用后台的子线程异步完成 fsync 的操作

always：always 策略不使用后台子线程来执行

![image-20220721161247092](img/image-20220721161247092.png)

**操作系统：swap**

增加单机物理机内存；使用集群

**操作系统：内存大页**

写时复制机制：一旦有数据要被修改，Redis 并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。开启内存大页的情况下：即使客户端请求只修改 100B 的数据，Redis 也需要拷贝2MB 的大页。

```shell
#always：内存大页被开启 never：未开启
cat /sys/kernel/mm/transparent_hugepage/enabled
#关闭内存大页机制
echo never /sys/kernel/mm/transparent_hugepage/enabled
```

# 删除数据后，为什么内存占用率还是很高？

内存碎片是如何形成的？

1. 内存分配器的分配策略；
2. 键值对大小不一样和删改操作

```shell
INFO memory
#碎片率
mem_fragmentation_ratio:1.86
```

```shell
#启用自动内存碎片清理
config set activedefrag yes
参数：
active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；
active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。
active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于25%，保证清理能正常开展；
active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。
```

# 缓冲区

**客户端输入和输出缓冲区**

避免客户端和服务端的请求发送和处理速度不匹配，服务器给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区。

![image-20220726095121048](img/image-20220726095121048.png)

**如何应对输入缓冲区溢出？**

诱因：

1. 写入bigkey；
2. 服务器端处理请求速度过慢

```shell
> CLIENT LIST
id=1843 addr=8.136.111.215:38980 laddr=172.25.142.192:6379 fd=8 name= age=217347 idle=261 flags=P db=5 sub=2 psub=1 multi=-1 qbuf=0 qbuf-free=0 argv-mem=0 obl=0 oll=0 omem=0 tot-mem=20504 events=r cmd=psubscribe user=default redir=-1
#cmd：客户端最新执行的命令 qbuf：缓冲区已经使用大小 qbuf-free：缓冲区尚未使用大小
```

1. 把缓冲区调大

   默认1GB无法调整

2. 避免客户端写入bigkey

**如何应对输出缓冲区溢出？**

输出缓冲区：包含大小16KB的固定缓冲空间(暂存OK响应和出错信息)；可以动态增加的缓冲空间(暂存大小可变的响应结果)。

诱因：

1. 服务器返回了bigkey的大量结果；

2. 执行了MONITOR命令；

   持续输出监测到的各个命令操作

3. 缓冲区大小设置不合理

   ```shell
   client-output-buffer-limit normal 0 0 0
   第 1 个 0 ：是缓冲区大小限制
   第 2 个 0 ：是缓冲区持续写入量限制
   第 3 个 0 ：是缓冲区持续写入时间限制
   ```

   订阅了Redis频道的订阅客户端

   ```shell
   client-output-buffer-limit pubsub 8mb 2mb 60
   pubsub：对订阅客户端设置
   8mb：实际占用缓冲区大小大于8mb，服务端直接关闭与客户端的连接
   2mb；60s：连续60s内对缓冲区的写入量超过2MB，服务端关闭客户端连接
   ```

**主从集群中的缓冲区**

- 复制缓冲区的溢出问题

  全量复制过程中，主节点向从节点传输RDB文件的同时，会继续接收客户端发送的命令请求。这些写命令会保存在复制缓冲区，等RDB文件传输完成后，再发送给从节点执行，主节点会为每个从节点都维护一个复制缓冲区。

  ![image-20220726104620415](img/image-20220726104620415.png)

  根据写命令数据的大小和应用的写命令速度，估计缓冲区中会积累的写命令数据量。

  1. 控制主节点保存数据大小，合理设置复制缓冲区大小；
  2. 控制从节点的数量。

- 复制积压缓冲区

  增量复制时使用的缓冲区

  主节点在把接收到的写命令同步给从节点时，同时会把这些命令写入复制积压缓冲区，一旦从节点发生网络闪断，再次和主节点恢复连接时，从节点会从复制积压缓冲区中，读取断连期间主节点接收到的写命令。

  ![image-20220726105456998](img/image-20220726105456998.png)

  复制积压缓冲区是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点重新开始执行全量复制。

  调整repl_backlog_size大小

# 答疑

## Redis 变慢的情况

1. 使用复杂度过高的命令或一次查询全量数据；
2. 操作bigkey；
3. 大量key集中过期；
4. 内存达到maxmemory；
5. 客户端使用短链接和Redis相连；
6. Redis实例数据量过大，RDB/AOF fork耗时严重；
7. AOF的写回策略为always；
8. Redis实例内存不足，导致使用swap；
9. 进程绑定CPU不合理；
10. Redis实例运行机器上开启了透明内存大页机制；
11. 网卡压力过大

## 如何使用慢查询日志和 latency monitor 排查执行慢的操作

**慢日志**

slowlog-log-slower-than：执行时间大于多少微妙的命令进行慢查询记录；

slowlog-max-len：慢查询日志最多能记录多少条命令 FIFO，默认128

```shell
> SLOWLOG GET 1
40 //日志的唯一ID编号
1656926423 //命令执行的时间戳
24453 //命令执行的时长，单位是微秒
SETBIT //具体执行的命令和参数
URL_BLOOM_FILTER
260963838
1
127.0.0.1:35166 //客户端的IP和端口号
 //客户端名称
```

**latency monitor**

```shell
#监控的命令执行时长阈值设为 1000 微秒
config set latency-monitor-threshold 1000

latency latest
1) 1) "command"
   2) (integer) 1600991500 //命令执行的时间戳
   3) (integer) 2500 //最近的超过阈值的延迟
   4) (integer) 10100 //最大的超过阈值的延迟
```

## 如何排查 Redis 的 bigkey?

1. ```shell
   ./redis-cli --bigkeys
   ```

2. SCAN

   LLEN

   SCARD

   ZCARD

   MEMORY USAGE user:info

# 数据库&缓存一致

**一致性**

1. 缓存中有数据，缓存的数据值需要和数据库中的值相同；
2. 缓存中本身没有数据，数据库中的值必须是最新值。

![删改数据](img/image-20220802104614190.png)

**如何解决数据不一致**

重试机制

把要删除或要更新的数据库值暂存到消息队列(Kafka)中，当应用没能成功删除缓存值时，从消息队列中重新读取值，再次进行删除。

![](img/image-20220802104942168.png)

高并发下，即使两步操作都没有失败，也可能读到不一致的数据。

1. **延迟双删**：先删除缓存，再更新数据库

   ![先删除缓存，再更新数据库](img/image-20220802105214085.png)

   **在线程A更新完数据库后，sleep一小段时间，再进行一次缓存删除。**线程A sleep的时间需要大于线程B读取数据再写入缓存的时间。

2. :star:先更新数据库，再删除缓存

   删除缓存操作比较快，对业务影响小。

   ![先更新数据库，再删除缓存](img/image-20220802105600123.png)

![总结](img/image-20220802105751962.png)

推荐先更新数据库再删除缓存：

1. 先删除缓存再更新数据库的话，缓存缺失，数据库压力增大；
2. 延迟双删等待时间不好设置；

强一致：更新数据库时，Redis客户端暂存并发读请求，数据库更新完毕、缓存值删除后，再读取数据。

# 缓存雪崩、击穿、穿透

**缓存雪崩**

大量的应用请求无法在Redis缓存中进行处理，大量请求发到数据库层，数据库压力激增。

- 缓存中有大量数据同时过期
  1. 数据过期时间增加一个较小的随机数(1-3分钟)；
  2. 服务降级
- Redis缓存实例宕机
  1. 业务系统实现服务熔断，请求限流；
  2. 事前预防：构建高可用集群

**缓存击穿**

某个访问非常频繁的热点数据，无法在缓存中进行处理，大量请求发送到数据库。

- 热点数据过期失效
  1. 特别频繁的热点数据不设置过期时间

**缓存穿透**

访问的数据不在Redis，也不在数据库中。

1. 缓存空值或缺省值；
2. 使用布隆过滤器判断数据是否存在，避免从数据库中查询是否存在；
3. 入口对请求合法性进行检查

![](img/image-20220802111221764.png)

# 缓存的淘汰

![image-20220803102405905](img/image-20220803102405905.png)

- noevction

  在使用的内存空间超过maxmemory值时，并不会淘汰数据，Redis不再提供服务，直接返回错误。

- volatilte-ttl

  设置了过期时间键值对，越早过期越先被删除。

- volatile-random

  设置了过期时间键值对，随机删除。

- volatile-lru

  设置了过期时间键值对，删除LRU(最近最少使用)。

- volatile-lfu

  设置了过期时间键值对，删除LFU(最不经常使用)。

- allkeys-random

  随机删除

- **allkeys-lru**

  LRU

- allkeys-lfu

  LFU

# Redis过期删除策略

- 定时删除

  在设置key的过期时间时，为该key创建一个定时器，定时器在key的过期时间来临时，对key进行删除；内存释放快，占用CPU，定时器创建耗时。

- 惰性删除

  key过期的时候不删除，获取key时检查是否过期，过期则删除，返回null；CPU占用少，占用内存。

- 定期删除

  每隔一段时间执行一次删除，redis.conf hz选项默认为10(即1s执行10次，100ms1次，值越大说明频率越快，Redis性能损耗越大)。

# 无锁的原子操作

加锁会导致系统并发性能降低

**Redis的两种原子操作方法**

1. 把多个操作在Redis中实现成单命令操作；
2. 把多个操作写到一个Lua脚本中。

# 分布式锁

**单节点**

单命令实现加锁：

```shell
SET lock_key unique_value NX PX 10000 (NX：不存在才会创建)
```

Lua脚本释放锁：

```lua
//释放锁 比较unique_value是否相等，避免误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
	return redis.call("del",KEYS[1])
else
	return 0
end
```

```shell
redis-cli --eval unlock.script lock_key, unique_value
```

**多节点**

Readlock

1. 客户端获取当前时间；

2. 客户端按顺序依次向N个Redis实例执行加锁操作(加锁操作设置超时时间)；

3. 计算整个加锁过程的总耗时，满足以下条件视为加锁成功：

   - 客户端从超过半数的Redis实例上成功获取到了锁；
   - 客户端获取锁的总耗时没有超过锁的有效时间

# Redis事务

MULTI：开启一个事务

EXEC：执行事务

**原子性**

1. 命令入队时就报错，会放弃事务执行，保证原子性；

   ```shell
   #开启事务
   127.0.0.1:6379> MULTI
   OK
   #发送事务中的第一个操作，但是Redis不支持该命令，返回报错信息
   127.0.0.1:6379> PUT a:stock 5
   (error) ERR unknown command `PUT`, with args beginning with: `a:stock`, `5`,
   #发送事务中的第二个操作，这个操作是正确的命令，Redis把该命令入队
   127.0.0.1:6379> DECR b:stock
   QUEUED
   #实际执行事务，但是之前命令有错误，所以Redis拒绝执行
   127.0.0.1:6379> EXEC
   (error) EXECABORT Transaction discarded because of previous errors.
   ```

2. 命令入队时没报错，实际执行时报错，不保证原子性；

   ```shell
   #开启事务
   127.0.0.1:6379> MULTI
   OK
   #发送事务中的第一个操作，LPOP命令操作的数据类型不匹配，此时并不报错
   127.0.0.1:6379> LPOP a:stock
   QUEUED
   #发送事务中的第二个操作
   127.0.0.1:6379> DECR b:stock
   QUEUED
   #实际执行事务，事务第一个操作执行报错
   127.0.0.1:6379> EXEC
   1) (error) WRONGTYPE Operation against a key holding the wrong kind of value
   2) (integer) 8
   ```

3. 在EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性。

**一致性**

在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的。

**隔离性**

WATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。

**持久性**

不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。

![](img/image-20220803141957628.png)

# 主从同步&故障切换

**主从数据不一致**

主从库间的命令复制是异步的

解决方案：

1. 硬件配置方面，尽量保证主从库间的网络连接状况；
2. 监控主从库间的复制进度

**读取过期数据**

惰性删除时，从库在服务读请求时，不会判断数据是否过期，而是会返回过期数据。Redis 3.2版本之后，从库虽然不会删除，但会返回空值。

EXPIRE和PEXPIRE：从命令执行时开始计算的存活时间；主从同步导致从库命令执行延迟。

EXPIREAT和PEXPIREAT：直接把数据的过期时间设置为具体一个时间点。时钟同步

![image-20220804105453969](img/image-20220804105453969.png)

**不合理的配置项**

1. protected-mode

   哨兵实例能否被其它服务器访问，yes：哨兵实例只能在部署的服务器本地进行访问，建议设置为no。

2. cluster-node-timeout

   Redis Cluster中实例响应心跳消息的超时时间，建议设置为10-20秒。

**总结**

![image-20220804110234354](img/image-20220804110234354.png)

# 脑裂

主从集群中，同时有两个主节点，它们都能接收写请求。客户端不知道该往哪个主节点写入数据，导致不同的客户端会往不同的主节点上写入数据，进一步导致数据丢失。

**为什么会发生脑裂？**

![image-20220805110648661](img/image-20220805110648661.png)

其它进程把机器的CPU资源用满(处理bigkey或发生内存swap)，导致Redis主库无法响应心跳，也无法处理请求，哨兵把主库判断为客观下线，开始主从切换。其它进程恢复正常，CPU资源释放，原主库开始正常服务请求，而此时哨兵还没完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作在原主库上写入数据。

**为什么脑裂会导致数据丢失？**

主从切换后，从库一旦升级为新主库，哨兵会让原主库执行slave of命名，和主库重新进行全量同步，而在全量同步执行的最后阶段，原主库需要清空本地数据，加载新主库发送的RDB文件。

![image-20220805111320814](img/image-20220805111320814.png)

**如何应对脑裂问题？**

min-slaves-to-write：主库能进行数据同步的最少从库数量；

min-slaves-max-lag：主从库进行数据复制时，从库给主库发送ACK消息的最大延迟(单位秒)

min-slaves-to-write：N  min-slaves-max-lag：T

主库连接的从库中至少有N个从库，和主库进行数据复制时的ACK消息延迟不能超过T秒，否则主库不再接收客户端请求。

建议：假设从库有K个，可以将min-slaves-to-write设置为K/2 + 1(K等于1，设为1)，将min-slaves-max-lag设置为10-20秒。

# 秒杀场景

**秒杀场景的负载特征对支撑系统的要求**

- **瞬时并发访问量非常高**

  当有大量并发请求涌入秒杀系统时，需要使用Redis先拦截大部分请求，避免大量请求直接发送给数据库，压垮数据库。

- **读多写少**

**Redis作用**

1. 秒杀活动前

   把商品详情页元素静态化，使用CDN或浏览器把静态元素缓存起来。

2. 秒杀活动开始

   不使用数据库扣减库存：1.数据库、Redis数据一致额外的开销；2.数据库处理慢，不能及时更新库存余量，下单量超过实际库存。在Redis中进行库存扣减。

3. 秒杀活动结束

![image-20220728163218400](img/image-20220728163218400.png)

**保证库存查验和库存扣减原子性执行**

Hash类型保存商品信息

```
key: itemID
value: {total: N, ordered: M}
//total 总库存量，ordered 已秒杀量
```

- Lua脚本

  ```lua
  #获取商品库存信息
  local counts = redis.call("HMGET", KEYS[1], "total", "ordered");
  #将总库存转换为数值
  local total = tonumber(counts[1])
  #将已被秒杀的库存转换为数值
  local ordered = tonumber(counts[2])
  #如果当前请求的库存量加上已被秒杀的库存量仍然小于总库存量，就可以更新库存
  if ordered + k <= total then
  #更新已秒杀的库存量
  redis.call("HINCRBY",KEYS[1],"ordered",k) ret
  end
  return 0
  ```

- 分布式锁

  客户端需要先向 Redis 请求锁，只有请求到了锁，才能进行库存查验等操作。

  ```java
  //使用商品ID作为key
  key = itemID
  //使用客户端唯一标识作为value
  val = clientUniqueID
  //申请分布式锁，Timeout是超时时间
  lock =acquireLock(key, val, Timeout)
  //当拿到锁后，才能进行库存查验和扣减
  if(lock == True) {
  //库存查验和扣减
  availStock = DECR(key, k)
  //库存已经扣减完了，释放锁，返回秒杀失败
  if (availStock < 0) {
  releaseLock(key, val)
  return error
  }else{
  //库存扣减成功，释放锁
  releaseLock(key, val)
  //订单处理
  }
  }else
  //没有拿到锁，直接返回
  return
  ```

# 好用的Redis运维工具

**监控命令：INFO**

![image-20220728164847322](img/image-20220728164847322.png)

`stat、commandstat、cpu、memory`

**面向Prometheus的Redis-exporter监控**

**数据迁移工具Redis-shake**

![image-20220728165429402](img/image-20220728165429402.png)

**集群管理工具 CacheCloud**

# 使用规范

**键值对使用规范**

- key的命名规范

  业务名:具体的业务数据名:key

  uv:page:1024

  控制key的长度，u代表user

- 避免bigkey

  String类型数据大小控制在10kb以下；集合类型元素个数在1万以下。

- 使用高效序列化方法和压缩方法

  protostuff和kryo

  XML和JSON格式的数据占用的内存空间比较大，压缩后再写入Redis。

- 使用整数对象共享池

**数据保存规范**

- 使用Redis保存热数据

- 不同的业务数据分实例存储

- 数据保存时设置过期时间

- 控制Redis实例的容量

   2-6GB

**命令使用规范**

- 线上禁用部分命令

  KEYS、FLUSHALL、FLUSHDB

  rename-command 命令在配置文件中对这些命令进行重命名，让客户端无法使用这些命令。

  替代：KEYS => SCAN、FLUSHALL、FLUSHDB => ASYNC

- 慎用MONITOR命令

- 慎用全量操作命令



